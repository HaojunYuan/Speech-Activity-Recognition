{"ast":null,"code":"var _jsxFileName = \"/Users/brian/Desktop/ML/CS4641/speech-activity-recognition/src/pages/FinalUpdate/FinalUpdate.js\",\n    _s = $RefreshSig$();\n\nimport React from \"react\";\nimport { Typography, Box } from \"@material-ui/core\";\nimport { makeStyles } from \"@material-ui/core/styles\";\nimport { Header } from \"../../components\";\nimport ref from \"../../img/references.png\";\nimport rfFI from \"../../img/rf_feature_importance.png\";\nimport adbFI from \"../../img/abd_feature_importance.png\";\nimport zcrFig from \"../../img/zcr.png\";\nimport rmsFig from \"../../img/rms.png\";\nimport spectralcentroidFig from \"../../img/spectralcentroid.png\";\nimport spectralrolloffFig from \"../../img/spectralrolloff.png\";\nimport mfccFig from \"../../img/mfcc.png\";\nimport mfccFig2 from \"../../img/mfcc2.png\";\nimport spectralcrest from \"../../img/spectralcrest.png\";\nimport trainingresult from \"../../img/trainingresult.png\";\nimport hyper from \"../../img/hyoer.png\"; //import { Link } from 'react-router-dom';\n\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst useStyles = makeStyles(theme => ({\n  wrapper: {\n    display: \"flex\",\n    alignItems: \"center\",\n    flexDirection: \"column\",\n    paddingTop: \"20px\"\n  },\n  tempWrapper: {\n    display: \"flex\",\n    alignItems: \"center\",\n    flexDirection: \"column\",\n    paddingTop: \"10%\"\n  },\n  link: {\n    textDecoration: \"none\",\n    color: \"#000\"\n  },\n  boxFormat: {\n    width: \"70%\" //paddingBottom:'20px',\n\n  },\n  titleFormat: {\n    paddingBottom: \"10px\",\n    textDecoration: \"none\",\n    color: \"#212F3C\" //fontFamily: '-apple-system',\n\n  },\n  lateTitleFormat: {\n    paddingTop: \"20px\",\n    paddingBottom: \"10px\",\n    textDecoration: \"none\",\n    color: \"#212F3C\" //fontFamily: '-apple-system',\n\n  },\n  titleParagraphFormat: {\n    fontFamily: \"-apple-system\"\n  },\n  titleParagraphFormat2: {\n    fontFamily: \"-apple-system\",\n    padding: \"10px\"\n  },\n  titleParagraphFormat3: {\n    fontFamily: \"-apple-system\",\n    padding: \"10px\",\n    fontWeight: \"bold\"\n  },\n  titleParagraphFormat4: {\n    fontFamily: \"-apple-system\",\n    paddingLeft: \"10px\"\n  },\n  imageFormat: {\n    width: \"50\",\n    height: \"50%\",\n    display: \"flex\",\n    alignItems: \"center\",\n    flexDirection: \"column\",\n    paddingTop: \"2%\"\n  },\n  imageFormat3: {\n    width: \"70%\",\n    height: \"70%\",\n    display: \"flex\",\n    alignItems: \"center\",\n    flexDirection: \"column\",\n    paddingTop: \"2%\"\n  },\n  imgwrapper: {\n    display: \"flex\",\n    alignItems: \"center\",\n    flexDirection: \"column\",\n    paddingTop: \"2%\"\n  },\n  refwrapper: {\n    display: \"flex\",\n    alignItems: \"center\",\n    flexDirection: \"column\"\n  },\n  refFormat: {\n    width: \"70%\",\n    height: \"70%\",\n    display: \"flex\",\n    alignItems: \"center\",\n    flexDirection: \"column\"\n  }\n}));\n\nconst FinalUpdate = ({\n  tagChange\n}) => {\n  _s();\n\n  const classes = useStyles(); //const theme = useTheme();\n\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: classes.wrapper,\n    children: [/*#__PURE__*/_jsxDEV(Header, {}, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 112,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(Box, {\n      className: classes.boxFormat,\n      children: [/*#__PURE__*/_jsxDEV(Typography, {\n        align: \"center\",\n        variant: \"h4\",\n        className: classes.titleFormat,\n        children: \"Introduction/Background\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 114,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"subtitle1\",\n        className: classes.titleParagraphFormat2,\n        children: \"Since the introduction of Siri, voice assistants have hugely impacted people's experience with intelligent systems. However, this sudden fad comes with challenges, with the most obvious one being distinguishing human voice from background noises and silence, which necessitates novel approaches to speech detection. To serve this endeavor, our project utilizes machine learning methods to perform human speech recognition against complex noise scenarios.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 117,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"center\",\n        variant: \"h4\",\n        className: classes.lateTitleFormat,\n        children: \"Problem Statement\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 131,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"subtitle1\",\n        className: classes.titleParagraphFormat2,\n        children: \"The fundamental problem is a binary classification. Given an audio source, we aim to distinguition the time intervals containing human speeches from the rest. Additionally, we would filter out background noises of timestamps that are identified as containing speeches.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 138,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"center\",\n        variant: \"h4\",\n        className: classes.lateTitleFormat,\n        children: \"Method\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 149,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"h5\",\n        className: classes.titleParagraphFormat,\n        children: \"Dataset\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 156,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"subtitle1\",\n        className: classes.titleParagraphFormat2,\n        children: [\"- Speech activity detection dataset from Kaggle: 3 sets of data, 738 files in total with their annotations\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 169,\n          columnNumber: 48\n        }, this), \"- Florida Bandmaster Association (FBA) dataset\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 170,\n          columnNumber: 36\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 163,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"h5\",\n        className: classes.titleParagraphFormat,\n        children: \"Working Process\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 173,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"subtitle1\",\n        className: classes.titleParagraphFormat2,\n        children: \"For training, accurate annotation of the segment boundaries separating noise, silence, and speech part is required and essential. The dataset we select includes annotation files in praat-textgrids form, so we first need to write a data-preprocessing file to read in these files and build a groundtruth matrix specifying labels of different parts of the audio. Meanwhile, we need to read in the audio file and create a sliding window moving on it, extracting features like mfcc and spectral flux from different time intervals. The next step is to feed our data to the pre-defined model to let the machine learn. We will split our dataset to two parts, maybe 80% for training and 20% for testing. Lastly, we will employ different evaluation methods in class to access our model.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 180,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"h5\",\n        className: classes.titleParagraphFormat,\n        children: [\" \", \"Training Method\"]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 199,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"subtitle1\",\n        className: classes.titleParagraphFormat2,\n        children: [\"Noise, silence and human speech have very different audio features. To distinguish them, we need to first understand how musical features map input datapoints to their groups before later applying these rules to classify hidden, or unseen inputs. \", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 215,\n          columnNumber: 46\n        }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 216,\n          columnNumber: 11\n        }, this), \"We will compare the performances of popular classification algorithms and then improve the winning model based on our specific use scenario.\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 219,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 220,\n          columnNumber: 11\n        }, this), \" General Approach: Supervised Learning\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 221,\n          columnNumber: 11\n        }, this), \" Candidate Models: SVM, Random Forest, CNN [1] \", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 221,\n          columnNumber: 67\n        }, this), \"Related Libraries: Numpy, Sklearn, Librosa\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 222,\n          columnNumber: 53\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 207,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"center\",\n        variant: \"h4\",\n        className: classes.lateTitleFormat,\n        children: \"Data Collection\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 225,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"h5\",\n        className: classes.titleParagraphFormat,\n        children: \"Data Preprocessing\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 232,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"subtitle1\",\n        className: classes.titleParagraphFormat2,\n        children: [\"To start off the project, we turn raw audio files into tabular data through signal processing techniques. In DataProcessing.py, we use librosa to load and convert each audio file into a float array. We then stack these arrays vertically and pad zero to those with shorter length, forming a regular audio matrix, with each row as a different audio file. We also return the average sampling rate in this file for later use. In TextfileRead.py, we import textgrid and use this to generate our groundtruth matrix. We achieve this by first constructing a dummy zero matrix with the same shape as the audio matrix. Then we read in different annotation files which label out every starting and ending time of the human speech. We time each timestamp with the sampling rate and get the index of the number we should start labeling 1. With this method, we go through all textgrid files and generate a equal-sized matrix with annotations (labels).\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 258,\n          columnNumber: 11\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 239,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"h5\",\n        className: classes.titleParagraphFormat,\n        children: \"Feature Extraction\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 261,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"subtitle1\",\n        className: classes.titleParagraphFormat2,\n        children: [\"To capture characteristics of audio files, we decided to generate 11 features which we think are crucial in classifying audio segment. These features are zcr, rms, spectral_centroid, spectral_runoff and 13 coefficients of mfcc. The various features that we have extracted are explained below. These features are common features that are associated with sound recognition and spectrogram analysis. The goal of the project is to separate speech audio from silences, we have noted that not all these features would be needed but as we are including data with noises, features such as mfcc improved the model when non-speech noises are introduced.\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 283,\n          columnNumber: 11\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 268,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"h5\",\n        className: classes.titleParagraphFormat,\n        children: \"Feature Details\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 286,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"subtitle1\",\n        className: classes.titleParagraphFormat2,\n        children: [\"All Ks here refer to the size of the processing block. And X(i) refers to the signal value generated by the Librosa load() function.\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 300,\n          columnNumber: 11\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 293,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"subtitle1\",\n        className: classes.titleParagraphFormat3,\n        children: \"Zero Crossing Rate (ZCR)\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 302,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"subtitle1\",\n        className: classes.titleParagraphFormat4,\n        children: [\"ZCR is a low-level feature describing the number of changes of sign in consecutive blocks of the audio samples.\", /*#__PURE__*/_jsxDEV(\"div\", {\n          className: classes.imgwrapper,\n          children: /*#__PURE__*/_jsxDEV(\"img\", {\n            className: classes.imageFormat3,\n            src: zcrFig,\n            alt: \"...\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 317,\n            columnNumber: 13\n          }, this)\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 316,\n          columnNumber: 11\n        }, this), \"This function describes how often the signal content changes its sign in the block. The bigger this value is, the more likely that this block contains human voice / sound (any high-frequency content).\"]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 309,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"subtitle1\",\n        className: classes.titleParagraphFormat3,\n        children: \"Root Mean Square (RMS)\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 324,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"subtitle1\",\n        className: classes.titleParagraphFormat4,\n        children: [\"RMS is also a low-level feature describing the intensity of the audio signal.\", /*#__PURE__*/_jsxDEV(\"div\", {\n          className: classes.imgwrapper,\n          children: /*#__PURE__*/_jsxDEV(\"img\", {\n            className: classes.imageFormat3,\n            src: rmsFig,\n            alt: \"...\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 339,\n            columnNumber: 13\n          }, this)\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 338,\n          columnNumber: 11\n        }, this), \"This function describes the root mean square of the signal value in a certain block. The higher this value is, the more likely there is audio in this time period. It also helps smooth out the audio, as the sharp increase of signal value will be smoothed out by other numbers in the same time range.\"]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 331,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"subtitle1\",\n        className: classes.titleParagraphFormat3,\n        children: \"Spectral Centroid\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 348,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"subtitle1\",\n        className: classes.titleParagraphFormat4,\n        children: [\"Spectral Centroid describes the center of gravity of the spectral energy, which is defined as the frequency-weighted sum of the power spectrum.\", /*#__PURE__*/_jsxDEV(\"div\", {\n          className: classes.imgwrapper,\n          children: /*#__PURE__*/_jsxDEV(\"img\", {\n            className: classes.imageFormat3,\n            src: spectralcentroidFig,\n            alt: \"...\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 364,\n            columnNumber: 13\n          }, this)\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 363,\n          columnNumber: 11\n        }, this), \"This feature describes the ratio of high-frequency to low-frequency in the certain block.\"]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 355,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"subtitle1\",\n        className: classes.titleParagraphFormat3,\n        children: \"Spectral Rolloff\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 374,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"subtitle1\",\n        className: classes.titleParagraphFormat4,\n        children: [\"The spectral rolloff measures the bandwidth of the analyzed block. It is described as the frequency bin below which the magnitudes of the short-time Fourier Transform of the x(i) reaches a certain percentage of the overall magnitude. Basically, it defines how much energy is lied under a specific frequency.\", /*#__PURE__*/_jsxDEV(\"div\", {\n          className: classes.imgwrapper,\n          children: /*#__PURE__*/_jsxDEV(\"img\", {\n            className: classes.imageFormat,\n            src: spectralrolloffFig,\n            alt: \"...\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 392,\n            columnNumber: 13\n          }, this)\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 391,\n          columnNumber: 11\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 381,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"subtitle1\",\n        className: classes.titleParagraphFormat3,\n        children: \"Mel-Frequency Cepstral Coefficients (MFCC)\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 400,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"subtitle1\",\n        className: classes.titleParagraphFormat4,\n        children: [/*#__PURE__*/_jsxDEV(\"div\", {\n          className: classes.imgwrapper,\n          children: /*#__PURE__*/_jsxDEV(\"img\", {\n            className: classes.imageFormat,\n            src: mfccFig,\n            alt: \"...\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 413,\n            columnNumber: 13\n          }, this)\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 412,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 415,\n          columnNumber: 11\n        }, this), \"MFCC is a series of coefficients describing the shape of the spectrogram of the audio. The jth coefficient is calculated using the following formula.\", /*#__PURE__*/_jsxDEV(\"div\", {\n          className: classes.imgwrapper,\n          children: /*#__PURE__*/_jsxDEV(\"img\", {\n            className: classes.imageFormat3,\n            src: mfccFig2,\n            alt: \"...\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 420,\n            columnNumber: 13\n          }, this)\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 419,\n          columnNumber: 11\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 407,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"subtitle1\",\n        className: classes.titleParagraphFormat3,\n        children: \"Spectral Flux\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 428,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"subtitle1\",\n        className: classes.titleParagraphFormat4,\n        children: \"Spectral flux defines the amount of change of the spectral shape, which is usually calculated by the average different between Fourier Transform frames. Spectral flux is also a good indicator describing the spectrogram shape of the audio signal.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 435,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"subtitle1\",\n        className: classes.titleParagraphFormat3,\n        children: \"Spectral Crest\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 446,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"subtitle1\",\n        className: classes.titleParagraphFormat4,\n        children: [\"Spectral crest factor measures the tonal characteristic. It compares the maximum magnitude of the power spectrum with the sum of the magnitude spectrum.\", /*#__PURE__*/_jsxDEV(\"div\", {\n          className: classes.imgwrapper,\n          children: /*#__PURE__*/_jsxDEV(\"img\", {\n            className: classes.imageFormat2,\n            src: spectralcrest,\n            alt: \"...\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 462,\n            columnNumber: 13\n          }, this)\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 461,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 468,\n          columnNumber: 11\n        }, this), \"Tonal characteristic generally refers to the ratio between tonal components and noisy components.\"]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 453,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"center\",\n        variant: \"h4\",\n        className: classes.lateTitleFormat,\n        children: \"Model Training\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 473,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"subtitle1\",\n        className: classes.titleParagraphFormat2,\n        children: [\"After pre-processing and feature extraction, we implemented three different training menthods to test results and evaluating outputs: Random Forest, Adaboost (Adaptive Boosting) and SVM (Support Vector Machine). We chose these model based on the idea that ensemble learning models excel non-ensemble models in solving classification problems (both bagging and boosting), and SVM is designed to work with high-dimension data and offers good generalization to avoiid overfitting, which is applicable to our use case.\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 493,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 494,\n          columnNumber: 11\n        }, this), \"Since we have 11 individual data sources with different features, in order to involve all possible situations (Male and Female, with and without background noise), we decided to combine all data files to generate one dataset with all information, given that all data files have 2 labels only: a row of data is labeled either \\\"true\\\" (speech) or \\\"false\\\" (non-speech).\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 501,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 502,\n          columnNumber: 11\n        }, this), \"For each of the three classification models mentioned above, we then conduct K-fold cross validation to split the dataset into 5 folds, leaving 80% of the data for training, and 20% for testing in each of the five trials. For each trial, we set the expected predictive model accordingly and apply evaulation metrics in order to take average in the end. Since our dataset is balanced and the models we use inherently work with unbalanced datasets, we only use Accuracy and F1 Score as performance metrics (see the following section).\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 511,\n          columnNumber: 11\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 480,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"center\",\n        variant: \"h4\",\n        className: classes.lateTitleFormat,\n        children: \"Performance Evaluation\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 514,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"subtitle1\",\n        className: classes.titleParagraphFormat2,\n        children: [\"We use 2 metrics to evaluate model performance: Average Accuracy and Average F1 score. The former one can show the correctness of our model predictions directly while the latter one informs us how precise the results are.\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 530,\n          columnNumber: 11\n        }, this), \"Evaluation results for three training models are shown in figure below. Noticed that all three Average Accuracy values are above 86% and all Average F-1 scores are above 87%, as shown in the figuure below.\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 535,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n          className: classes.imgwrapper,\n          children: /*#__PURE__*/_jsxDEV(\"img\", {\n            className: classes.imageFormat3,\n            src: trainingresult,\n            alt: \"...\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 537,\n            columnNumber: 13\n          }, this)\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 536,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 543,\n          columnNumber: 11\n        }, this), \"We also calculate feature importances during each trial so that we can understand what features influence predictions the most and reevaluate our working during the \\\"Data Preprocessing\\\" and \\\"Feature Extraction\\\" stages. //////To gain insights into how individual features contribute to classification, we generate feature importances of our selected features with our Random Forest classifier and Adaboost classiifier (as shown below).\", /*#__PURE__*/_jsxDEV(\"div\", {\n          className: classes.imgwrapper,\n          children: /*#__PURE__*/_jsxDEV(\"img\", {\n            className: classes.imageFormat3,\n            src: rfFI,\n            alt: \"...\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 552,\n            columnNumber: 13\n          }, this)\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 551,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n          className: classes.imgwrapper,\n          children: /*#__PURE__*/_jsxDEV(\"img\", {\n            className: classes.imageFormat3,\n            src: adbFI,\n            alt: \"...\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 555,\n            columnNumber: 13\n          }, this)\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 554,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 557,\n          columnNumber: 11\n        }, this), \"We observe that both models believe Root Mean Square (RMS) of audio signal intensity to be more important in classifying human speeches compared to other features, while the models do not agree on the importance of Spectral Flux and Spectral Centroid.\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 562,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 563,\n          columnNumber: 11\n        }, this), \"Since Random Forest classifier yields the best performance according to our metrics, focus on this classifier exclusively and try to optimize the model throughconducting hyperparameter tuning. We set different hyperparameters values (n, split and leaf values) and did six trials in total. All the six trials results had an accuracy above 90% for PCA = 8 or PCA = 10, which means that our model had a high quality of predicting outputs such that it won't change in a big scale for different hyperparameters values. Plots for the model accuracy for six trials are shown in figure below.\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 573,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n          className: classes.imgwrapper,\n          children: /*#__PURE__*/_jsxDEV(\"img\", {\n            className: classes.imageFormat,\n            src: hyper,\n            alt: \"...\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 575,\n            columnNumber: 13\n          }, this)\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 574,\n          columnNumber: 11\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 521,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"center\",\n        variant: \"h4\",\n        className: classes.lateTitleFormat,\n        children: \"Conclusion\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 579,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"subtitle1\",\n        className: classes.titleParagraphFormat2,\n        children: \"Since all three predictive models we set have pretty high average accuracy (above 86%) and average F-1 (above 87%) values, we believe our models can produce reliable predictions on whether a certain time interval has human speeching audio or not given a random speeching audio input. Among the three training models, Random Forest has the best output results (above 90.5% accuracy and 90.8% F-1 scores). We believe this is because the provided resource dataset is very large, which allow the training model to avoid overfitting and learn the data comprehensively. Also, the feature importances plots we set during our \\\"Data Preprocessing\\\" and \\\"Model Training\\\" stages allow the model to remove irrelevant attributes and focus on features that have bigger influences to perform in a better way.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 586,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"center\",\n        variant: \"h4\",\n        className: classes.lateTitleFormat,\n        children: \"Timeline and Team Work Assignment\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 604,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"h5\",\n        className: classes.titleParagraphFormat,\n        children: \"Proposal (October 7th)\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 611,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"subtitle1\",\n        className: classes.titleParagraphFormat2,\n        children: [\"Dataset, approach, report - October 3rd\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 624,\n          columnNumber: 11\n        }, this), \"Review cotent and finish proposal - October 7th\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 626,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 627,\n          columnNumber: 11\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 618,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"h5\",\n        className: classes.titleParagraphFormat,\n        children: \"Midterm Report (November 16th)\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 630,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"subtitle1\",\n        className: classes.titleParagraphFormat2,\n        children: [\"Research and architectural design (Team) - October 15th\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 643,\n          columnNumber: 11\n        }, this), \"Data collection and preprocessing (Haojun, Yulong) - October 31st\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 645,\n          columnNumber: 11\n        }, this), \"Train and validate first approach and finish report after evaluation (Bruce, Zeyu, Yulai) - November 16th\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 648,\n          columnNumber: 11\n        }, this), \"Further improve our model by adjusting parameters and optimizing the code (Team) - November 21th\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 651,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 652,\n          columnNumber: 11\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 637,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"h5\",\n        className: classes.titleParagraphFormat,\n        children: \"Final Report (December 7th)\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 655,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"subtitle1\",\n        className: classes.titleParagraphFormat2,\n        children: [\"Add distinguishing feature of approach (Team) - November 25th\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 668,\n          columnNumber: 11\n        }, this), \"Review entire project and finish final report (Team) - December 7th\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 670,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 671,\n          columnNumber: 11\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 662,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"center\",\n        variant: \"h4\",\n        className: classes.lateTitleFormat,\n        children: \"References\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 674,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n        className: classes.refwrapper,\n        children: /*#__PURE__*/_jsxDEV(\"img\", {\n          className: classes.refFormat,\n          src: ref,\n          alt: \"...\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 682,\n          columnNumber: 11\n        }, this)\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 681,\n        columnNumber: 9\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 113,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 111,\n    columnNumber: 5\n  }, this);\n};\n\n_s(FinalUpdate, \"8g5FPXexvSEOsxdmU7HicukHGqY=\", false, function () {\n  return [useStyles];\n});\n\n_c = FinalUpdate;\nexport default FinalUpdate;\n\nvar _c;\n\n$RefreshReg$(_c, \"FinalUpdate\");","map":{"version":3,"sources":["/Users/brian/Desktop/ML/CS4641/speech-activity-recognition/src/pages/FinalUpdate/FinalUpdate.js"],"names":["React","Typography","Box","makeStyles","Header","ref","rfFI","adbFI","zcrFig","rmsFig","spectralcentroidFig","spectralrolloffFig","mfccFig","mfccFig2","spectralcrest","trainingresult","hyper","useStyles","theme","wrapper","display","alignItems","flexDirection","paddingTop","tempWrapper","link","textDecoration","color","boxFormat","width","titleFormat","paddingBottom","lateTitleFormat","titleParagraphFormat","fontFamily","titleParagraphFormat2","padding","titleParagraphFormat3","fontWeight","titleParagraphFormat4","paddingLeft","imageFormat","height","imageFormat3","imgwrapper","refwrapper","refFormat","FinalUpdate","tagChange","classes","imageFormat2"],"mappings":";;;AAAA,OAAOA,KAAP,MAAkB,OAAlB;AAEA,SAASC,UAAT,EAAqBC,GAArB,QAAgC,mBAAhC;AACA,SAASC,UAAT,QAA2B,0BAA3B;AACA,SAASC,MAAT,QAAuB,kBAAvB;AACA,OAAOC,GAAP,MAAgB,0BAAhB;AACA,OAAOC,IAAP,MAAiB,qCAAjB;AACA,OAAOC,KAAP,MAAkB,sCAAlB;AACA,OAAOC,MAAP,MAAmB,mBAAnB;AACA,OAAOC,MAAP,MAAmB,mBAAnB;AACA,OAAOC,mBAAP,MAAgC,gCAAhC;AACA,OAAOC,kBAAP,MAA+B,+BAA/B;AACA,OAAOC,OAAP,MAAoB,oBAApB;AACA,OAAOC,QAAP,MAAqB,qBAArB;AACA,OAAOC,aAAP,MAA0B,6BAA1B;AACA,OAAOC,cAAP,MAA2B,8BAA3B;AACA,OAAOC,KAAP,MAAkB,qBAAlB,C,CACA;;;AAEA,MAAMC,SAAS,GAAGd,UAAU,CAAEe,KAAD,KAAY;AACvCC,EAAAA,OAAO,EAAE;AACPC,IAAAA,OAAO,EAAE,MADF;AAEPC,IAAAA,UAAU,EAAE,QAFL;AAGPC,IAAAA,aAAa,EAAE,QAHR;AAIPC,IAAAA,UAAU,EAAE;AAJL,GAD8B;AAOvCC,EAAAA,WAAW,EAAE;AACXJ,IAAAA,OAAO,EAAE,MADE;AAEXC,IAAAA,UAAU,EAAE,QAFD;AAGXC,IAAAA,aAAa,EAAE,QAHJ;AAIXC,IAAAA,UAAU,EAAE;AAJD,GAP0B;AAavCE,EAAAA,IAAI,EAAE;AACJC,IAAAA,cAAc,EAAE,MADZ;AAEJC,IAAAA,KAAK,EAAE;AAFH,GAbiC;AAiBvCC,EAAAA,SAAS,EAAE;AACTC,IAAAA,KAAK,EAAE,KADE,CAET;;AAFS,GAjB4B;AAqBvCC,EAAAA,WAAW,EAAE;AACXC,IAAAA,aAAa,EAAE,MADJ;AAEXL,IAAAA,cAAc,EAAE,MAFL;AAGXC,IAAAA,KAAK,EAAE,SAHI,CAIX;;AAJW,GArB0B;AA2BvCK,EAAAA,eAAe,EAAE;AACfT,IAAAA,UAAU,EAAE,MADG;AAEfQ,IAAAA,aAAa,EAAE,MAFA;AAGfL,IAAAA,cAAc,EAAE,MAHD;AAIfC,IAAAA,KAAK,EAAE,SAJQ,CAKf;;AALe,GA3BsB;AAkCvCM,EAAAA,oBAAoB,EAAE;AACpBC,IAAAA,UAAU,EAAE;AADQ,GAlCiB;AAqCvCC,EAAAA,qBAAqB,EAAE;AACrBD,IAAAA,UAAU,EAAE,eADS;AAErBE,IAAAA,OAAO,EAAE;AAFY,GArCgB;AAyCvCC,EAAAA,qBAAqB,EAAE;AACrBH,IAAAA,UAAU,EAAE,eADS;AAErBE,IAAAA,OAAO,EAAE,MAFY;AAGrBE,IAAAA,UAAU,EAAE;AAHS,GAzCgB;AA8CvCC,EAAAA,qBAAqB,EAAE;AACrBL,IAAAA,UAAU,EAAE,eADS;AAErBM,IAAAA,WAAW,EAAE;AAFQ,GA9CgB;AAkDvCC,EAAAA,WAAW,EAAE;AACXZ,IAAAA,KAAK,EAAE,IADI;AAEXa,IAAAA,MAAM,EAAE,KAFG;AAGXtB,IAAAA,OAAO,EAAE,MAHE;AAIXC,IAAAA,UAAU,EAAE,QAJD;AAKXC,IAAAA,aAAa,EAAE,QALJ;AAMXC,IAAAA,UAAU,EAAE;AAND,GAlD0B;AA0DvCoB,EAAAA,YAAY,EAAE;AACZd,IAAAA,KAAK,EAAE,KADK;AAEZa,IAAAA,MAAM,EAAE,KAFI;AAGZtB,IAAAA,OAAO,EAAE,MAHG;AAIZC,IAAAA,UAAU,EAAE,QAJA;AAKZC,IAAAA,aAAa,EAAE,QALH;AAMZC,IAAAA,UAAU,EAAE;AANA,GA1DyB;AAkEvCqB,EAAAA,UAAU,EAAE;AACVxB,IAAAA,OAAO,EAAE,MADC;AAEVC,IAAAA,UAAU,EAAE,QAFF;AAGVC,IAAAA,aAAa,EAAE,QAHL;AAIVC,IAAAA,UAAU,EAAE;AAJF,GAlE2B;AAwEvCsB,EAAAA,UAAU,EAAE;AACVzB,IAAAA,OAAO,EAAE,MADC;AAEVC,IAAAA,UAAU,EAAE,QAFF;AAGVC,IAAAA,aAAa,EAAE;AAHL,GAxE2B;AA6EvCwB,EAAAA,SAAS,EAAE;AACTjB,IAAAA,KAAK,EAAE,KADE;AAETa,IAAAA,MAAM,EAAE,KAFC;AAGTtB,IAAAA,OAAO,EAAE,MAHA;AAITC,IAAAA,UAAU,EAAE,QAJH;AAKTC,IAAAA,aAAa,EAAE;AALN;AA7E4B,CAAZ,CAAD,CAA5B;;AAsFA,MAAMyB,WAAW,GAAG,CAAC;AAAEC,EAAAA;AAAF,CAAD,KAAmB;AAAA;;AACrC,QAAMC,OAAO,GAAGhC,SAAS,EAAzB,CADqC,CAErC;;AAEA,sBACE;AAAK,IAAA,SAAS,EAAEgC,OAAO,CAAC9B,OAAxB;AAAA,4BACE,QAAC,MAAD;AAAA;AAAA;AAAA;AAAA,YADF,eAEE,QAAC,GAAD;AAAK,MAAA,SAAS,EAAE8B,OAAO,CAACrB,SAAxB;AAAA,8BACE,QAAC,UAAD;AAAY,QAAA,KAAK,EAAC,QAAlB;AAA2B,QAAA,OAAO,EAAC,IAAnC;AAAwC,QAAA,SAAS,EAAEqB,OAAO,CAACnB,WAA3D;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cADF,eAIE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,WAFV;AAGE,QAAA,SAAS,EAAEmB,OAAO,CAACd,qBAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAJF,eAkBE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,QADR;AAEE,QAAA,OAAO,EAAC,IAFV;AAGE,QAAA,SAAS,EAAEc,OAAO,CAACjB,eAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAlBF,eAyBE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,WAFV;AAGE,QAAA,SAAS,EAAEiB,OAAO,CAACd,qBAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAzBF,eAoCE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,QADR;AAEE,QAAA,OAAO,EAAC,IAFV;AAGE,QAAA,SAAS,EAAEc,OAAO,CAACjB,eAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cApCF,eA2CE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,IAFV;AAGE,QAAA,SAAS,EAAEiB,OAAO,CAAChB,oBAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cA3CF,eAkDE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,WAFV;AAGE,QAAA,SAAS,EAAEgB,OAAO,CAACd,qBAHrB;AAAA,8IAMuC;AAAA;AAAA;AAAA;AAAA,gBANvC,iEAO2B;AAAA;AAAA;AAAA;AAAA,gBAP3B;AAAA;AAAA;AAAA;AAAA;AAAA,cAlDF,eA4DE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,IAFV;AAGE,QAAA,SAAS,EAAEc,OAAO,CAAChB,oBAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cA5DF,eAmEE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,WAFV;AAGE,QAAA,SAAS,EAAEgB,OAAO,CAACd,qBAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAnEF,eAsFE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,IAFV;AAGE,QAAA,SAAS,EAAEc,OAAO,CAAChB,oBAHrB;AAAA,mBAKG,GALH;AAAA;AAAA;AAAA;AAAA;AAAA,cAtFF,eA8FE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,WAFV;AAGE,QAAA,SAAS,EAAEgB,OAAO,CAACd,qBAHrB;AAAA,2RAQqC;AAAA;AAAA;AAAA;AAAA,gBARrC,eASE;AAAA;AAAA;AAAA;AAAA,gBATF,+JAYE;AAAA;AAAA;AAAA;AAAA,gBAZF,eAaE;AAAA;AAAA;AAAA;AAAA,gBAbF,yDAcE;AAAA;AAAA;AAAA;AAAA,gBAdF,kEAc0D;AAAA;AAAA;AAAA;AAAA,gBAd1D,6DAe4C;AAAA;AAAA;AAAA;AAAA,gBAf5C;AAAA;AAAA;AAAA;AAAA;AAAA,cA9FF,eAgHE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,QADR;AAEE,QAAA,OAAO,EAAC,IAFV;AAGE,QAAA,SAAS,EAAEc,OAAO,CAACjB,eAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAhHF,eAuHE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,IAFV;AAGE,QAAA,SAAS,EAAEiB,OAAO,CAAChB,oBAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAvHF,eA8HE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,WAFV;AAGE,QAAA,SAAS,EAAEgB,OAAO,CAACd,qBAHrB;AAAA,68BAmBE;AAAA;AAAA;AAAA;AAAA,gBAnBF;AAAA;AAAA;AAAA;AAAA;AAAA,cA9HF,eAoJE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,IAFV;AAGE,QAAA,SAAS,EAAEc,OAAO,CAAChB,oBAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cApJF,eA2JE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,WAFV;AAGE,QAAA,SAAS,EAAEgB,OAAO,CAACd,qBAHrB;AAAA,uqBAeE;AAAA;AAAA;AAAA;AAAA,gBAfF;AAAA;AAAA;AAAA;AAAA;AAAA,cA3JF,eA6KE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,IAFV;AAGE,QAAA,SAAS,EAAEc,OAAO,CAAChB,oBAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cA7KF,eAoLE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,WAFV;AAGE,QAAA,SAAS,EAAEgB,OAAO,CAACd,qBAHrB;AAAA,wKAOE;AAAA;AAAA;AAAA;AAAA,gBAPF;AAAA;AAAA;AAAA;AAAA;AAAA,cApLF,eA6LE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,WAFV;AAGE,QAAA,SAAS,EAAEc,OAAO,CAACZ,qBAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cA7LF,eAoME,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,WAFV;AAGE,QAAA,SAAS,EAAEY,OAAO,CAACV,qBAHrB;AAAA,mJAOE;AAAK,UAAA,SAAS,EAAEU,OAAO,CAACL,UAAxB;AAAA,iCACE;AAAK,YAAA,SAAS,EAAEK,OAAO,CAACN,YAAxB;AAAsC,YAAA,GAAG,EAAEnC,MAA3C;AAAmD,YAAA,GAAG,EAAC;AAAvD;AAAA;AAAA;AAAA;AAAA;AADF;AAAA;AAAA;AAAA;AAAA,gBAPF;AAAA;AAAA;AAAA;AAAA;AAAA,cApMF,eAmNE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,WAFV;AAGE,QAAA,SAAS,EAAEyC,OAAO,CAACZ,qBAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAnNF,eA0NE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,WAFV;AAGE,QAAA,SAAS,EAAEY,OAAO,CAACV,qBAHrB;AAAA,iHAOE;AAAK,UAAA,SAAS,EAAEU,OAAO,CAACL,UAAxB;AAAA,iCACE;AAAK,YAAA,SAAS,EAAEK,OAAO,CAACN,YAAxB;AAAsC,YAAA,GAAG,EAAElC,MAA3C;AAAmD,YAAA,GAAG,EAAC;AAAvD;AAAA;AAAA;AAAA;AAAA;AADF;AAAA;AAAA;AAAA;AAAA,gBAPF;AAAA;AAAA;AAAA;AAAA;AAAA,cA1NF,eA2OE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,WAFV;AAGE,QAAA,SAAS,EAAEwC,OAAO,CAACZ,qBAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cA3OF,eAkPE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,WAFV;AAGE,QAAA,SAAS,EAAEY,OAAO,CAACV,qBAHrB;AAAA,mLAQE;AAAK,UAAA,SAAS,EAAEU,OAAO,CAACL,UAAxB;AAAA,iCACE;AACE,YAAA,SAAS,EAAEK,OAAO,CAACN,YADrB;AAEE,YAAA,GAAG,EAAEjC,mBAFP;AAGE,YAAA,GAAG,EAAC;AAHN;AAAA;AAAA;AAAA;AAAA;AADF;AAAA;AAAA;AAAA;AAAA,gBARF;AAAA;AAAA;AAAA;AAAA;AAAA,cAlPF,eAqQE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,WAFV;AAGE,QAAA,SAAS,EAAEuC,OAAO,CAACZ,qBAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cArQF,eA4QE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,WAFV;AAGE,QAAA,SAAS,EAAEY,OAAO,CAACV,qBAHrB;AAAA,uVAUE;AAAK,UAAA,SAAS,EAAEU,OAAO,CAACL,UAAxB;AAAA,iCACE;AACE,YAAA,SAAS,EAAEK,OAAO,CAACR,WADrB;AAEE,YAAA,GAAG,EAAE9B,kBAFP;AAGE,YAAA,GAAG,EAAC;AAHN;AAAA;AAAA;AAAA;AAAA;AADF;AAAA;AAAA;AAAA;AAAA,gBAVF;AAAA;AAAA;AAAA;AAAA;AAAA,cA5QF,eA+RE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,WAFV;AAGE,QAAA,SAAS,EAAEsC,OAAO,CAACZ,qBAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cA/RF,eAsSE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,WAFV;AAGE,QAAA,SAAS,EAAEY,OAAO,CAACV,qBAHrB;AAAA,gCAKE;AAAK,UAAA,SAAS,EAAEU,OAAO,CAACL,UAAxB;AAAA,iCACE;AAAK,YAAA,SAAS,EAAEK,OAAO,CAACR,WAAxB;AAAqC,YAAA,GAAG,EAAE7B,OAA1C;AAAmD,YAAA,GAAG,EAAC;AAAvD;AAAA;AAAA;AAAA;AAAA;AADF;AAAA;AAAA;AAAA;AAAA,gBALF,eAQE;AAAA;AAAA;AAAA;AAAA,gBARF,wKAYE;AAAK,UAAA,SAAS,EAAEqC,OAAO,CAACL,UAAxB;AAAA,iCACE;AACE,YAAA,SAAS,EAAEK,OAAO,CAACN,YADrB;AAEE,YAAA,GAAG,EAAE9B,QAFP;AAGE,YAAA,GAAG,EAAC;AAHN;AAAA;AAAA;AAAA;AAAA;AADF;AAAA;AAAA;AAAA;AAAA,gBAZF;AAAA;AAAA;AAAA;AAAA;AAAA,cAtSF,eA2TE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,WAFV;AAGE,QAAA,SAAS,EAAEoC,OAAO,CAACZ,qBAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cA3TF,eAkUE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,WAFV;AAGE,QAAA,SAAS,EAAEY,OAAO,CAACV,qBAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAlUF,eA6UE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,WAFV;AAGE,QAAA,SAAS,EAAEU,OAAO,CAACZ,qBAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cA7UF,eAoVE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,WAFV;AAGE,QAAA,SAAS,EAAEY,OAAO,CAACV,qBAHrB;AAAA,4LAQE;AAAK,UAAA,SAAS,EAAEU,OAAO,CAACL,UAAxB;AAAA,iCACE;AACE,YAAA,SAAS,EAAEK,OAAO,CAACC,YADrB;AAEE,YAAA,GAAG,EAAEpC,aAFP;AAGE,YAAA,GAAG,EAAC;AAHN;AAAA;AAAA;AAAA;AAAA;AADF;AAAA;AAAA;AAAA;AAAA,gBARF,eAeE;AAAA;AAAA;AAAA;AAAA,gBAfF;AAAA;AAAA;AAAA;AAAA;AAAA,cApVF,eAwWE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,QADR;AAEE,QAAA,OAAO,EAAC,IAFV;AAGE,QAAA,SAAS,EAAEmC,OAAO,CAACjB,eAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAxWF,eA+WE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,WAFV;AAGE,QAAA,SAAS,EAAEiB,OAAO,CAACd,qBAHrB;AAAA,siBAaE;AAAA;AAAA;AAAA;AAAA,gBAbF,eAcE;AAAA;AAAA;AAAA;AAAA,gBAdF,oYAqBE;AAAA;AAAA;AAAA;AAAA,gBArBF,eAsBE;AAAA;AAAA;AAAA;AAAA,gBAtBF,uiBA+BE;AAAA;AAAA;AAAA;AAAA,gBA/BF;AAAA;AAAA;AAAA;AAAA;AAAA,cA/WF,eAiZE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,QADR;AAEE,QAAA,OAAO,EAAC,IAFV;AAGE,QAAA,SAAS,EAAEc,OAAO,CAACjB,eAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAjZF,eAwZE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,WAFV;AAGE,QAAA,SAAS,EAAEiB,OAAO,CAACd,qBAHrB;AAAA,iQASE;AAAA;AAAA;AAAA;AAAA,gBATF,gOAcE;AAAA;AAAA;AAAA;AAAA,gBAdF,eAeE;AAAK,UAAA,SAAS,EAAEc,OAAO,CAACL,UAAxB;AAAA,iCACE;AACE,YAAA,SAAS,EAAEK,OAAO,CAACN,YADrB;AAEE,YAAA,GAAG,EAAE5B,cAFP;AAGE,YAAA,GAAG,EAAC;AAHN;AAAA;AAAA;AAAA;AAAA;AADF;AAAA;AAAA;AAAA;AAAA,gBAfF,eAsBE;AAAA;AAAA;AAAA;AAAA,gBAtBF,ycA8BE;AAAK,UAAA,SAAS,EAAEkC,OAAO,CAACL,UAAxB;AAAA,iCACE;AAAK,YAAA,SAAS,EAAEK,OAAO,CAACN,YAAxB;AAAsC,YAAA,GAAG,EAAErC,IAA3C;AAAiD,YAAA,GAAG,EAAC;AAArD;AAAA;AAAA;AAAA;AAAA;AADF;AAAA;AAAA;AAAA;AAAA,gBA9BF,eAiCE;AAAK,UAAA,SAAS,EAAE2C,OAAO,CAACL,UAAxB;AAAA,iCACE;AAAK,YAAA,SAAS,EAAEK,OAAO,CAACN,YAAxB;AAAsC,YAAA,GAAG,EAAEpC,KAA3C;AAAkD,YAAA,GAAG,EAAC;AAAtD;AAAA;AAAA;AAAA;AAAA;AADF;AAAA;AAAA;AAAA;AAAA,gBAjCF,eAoCE;AAAA;AAAA;AAAA;AAAA,gBApCF,8QAyCE;AAAA;AAAA;AAAA;AAAA,gBAzCF,eA0CE;AAAA;AAAA;AAAA;AAAA,gBA1CF,2lBAoDE;AAAA;AAAA;AAAA;AAAA,gBApDF,eAqDE;AAAK,UAAA,SAAS,EAAE0C,OAAO,CAACL,UAAxB;AAAA,iCACE;AAAK,YAAA,SAAS,EAAEK,OAAO,CAACR,WAAxB;AAAqC,YAAA,GAAG,EAAEzB,KAA1C;AAAiD,YAAA,GAAG,EAAC;AAArD;AAAA;AAAA;AAAA;AAAA;AADF;AAAA;AAAA;AAAA;AAAA,gBArDF;AAAA;AAAA;AAAA;AAAA;AAAA,cAxZF,eAkdE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,QADR;AAEE,QAAA,OAAO,EAAC,IAFV;AAGE,QAAA,SAAS,EAAEiC,OAAO,CAACjB,eAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAldF,eAydE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,WAFV;AAGE,QAAA,SAAS,EAAEiB,OAAO,CAACd,qBAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAzdF,eA2eE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,QADR;AAEE,QAAA,OAAO,EAAC,IAFV;AAGE,QAAA,SAAS,EAAEc,OAAO,CAACjB,eAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cA3eF,eAkfE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,IAFV;AAGE,QAAA,SAAS,EAAEiB,OAAO,CAAChB,oBAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAlfF,eAyfE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,WAFV;AAGE,QAAA,SAAS,EAAEgB,OAAO,CAACd,qBAHrB;AAAA,2EAME;AAAA;AAAA;AAAA;AAAA,gBANF,kEAQE;AAAA;AAAA;AAAA;AAAA,gBARF,eASE;AAAA;AAAA;AAAA;AAAA,gBATF;AAAA;AAAA;AAAA;AAAA;AAAA,cAzfF,eAqgBE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,IAFV;AAGE,QAAA,SAAS,EAAEc,OAAO,CAAChB,oBAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cArgBF,eA4gBE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,WAFV;AAGE,QAAA,SAAS,EAAEgB,OAAO,CAACd,qBAHrB;AAAA,2FAME;AAAA;AAAA;AAAA;AAAA,gBANF,oFAQE;AAAA;AAAA;AAAA;AAAA,gBARF,4HAWE;AAAA;AAAA;AAAA;AAAA,gBAXF,mHAcE;AAAA;AAAA;AAAA;AAAA,gBAdF,eAeE;AAAA;AAAA;AAAA;AAAA,gBAfF;AAAA;AAAA;AAAA;AAAA;AAAA,cA5gBF,eA8hBE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,IAFV;AAGE,QAAA,SAAS,EAAEc,OAAO,CAAChB,oBAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cA9hBF,eAqiBE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,WAFV;AAGE,QAAA,SAAS,EAAEgB,OAAO,CAACd,qBAHrB;AAAA,iGAME;AAAA;AAAA;AAAA;AAAA,gBANF,sFAQE;AAAA;AAAA;AAAA;AAAA,gBARF,eASE;AAAA;AAAA;AAAA;AAAA,gBATF;AAAA;AAAA;AAAA;AAAA;AAAA,cAriBF,eAijBE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,QADR;AAEE,QAAA,OAAO,EAAC,IAFV;AAGE,QAAA,SAAS,EAAEc,OAAO,CAACjB,eAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAjjBF,eAwjBE;AAAK,QAAA,SAAS,EAAEiB,OAAO,CAACJ,UAAxB;AAAA,+BACE;AAAK,UAAA,SAAS,EAAEI,OAAO,CAACH,SAAxB;AAAmC,UAAA,GAAG,EAAEzC,GAAxC;AAA6C,UAAA,GAAG,EAAC;AAAjD;AAAA;AAAA;AAAA;AAAA;AADF;AAAA;AAAA;AAAA;AAAA,cAxjBF;AAAA;AAAA;AAAA;AAAA;AAAA,YAFF;AAAA;AAAA;AAAA;AAAA;AAAA,UADF;AAikBD,CArkBD;;GAAM0C,W;UACY9B,S;;;KADZ8B,W;AAukBN,eAAeA,WAAf","sourcesContent":["import React from \"react\";\n\nimport { Typography, Box } from \"@material-ui/core\";\nimport { makeStyles } from \"@material-ui/core/styles\";\nimport { Header } from \"../../components\";\nimport ref from \"../../img/references.png\";\nimport rfFI from \"../../img/rf_feature_importance.png\";\nimport adbFI from \"../../img/abd_feature_importance.png\";\nimport zcrFig from \"../../img/zcr.png\";\nimport rmsFig from \"../../img/rms.png\";\nimport spectralcentroidFig from \"../../img/spectralcentroid.png\";\nimport spectralrolloffFig from \"../../img/spectralrolloff.png\";\nimport mfccFig from \"../../img/mfcc.png\";\nimport mfccFig2 from \"../../img/mfcc2.png\";\nimport spectralcrest from \"../../img/spectralcrest.png\";\nimport trainingresult from \"../../img/trainingresult.png\";\nimport hyper from \"../../img/hyoer.png\";\n//import { Link } from 'react-router-dom';\n\nconst useStyles = makeStyles((theme) => ({\n  wrapper: {\n    display: \"flex\",\n    alignItems: \"center\",\n    flexDirection: \"column\",\n    paddingTop: \"20px\",\n  },\n  tempWrapper: {\n    display: \"flex\",\n    alignItems: \"center\",\n    flexDirection: \"column\",\n    paddingTop: \"10%\",\n  },\n  link: {\n    textDecoration: \"none\",\n    color: \"#000\",\n  },\n  boxFormat: {\n    width: \"70%\",\n    //paddingBottom:'20px',\n  },\n  titleFormat: {\n    paddingBottom: \"10px\",\n    textDecoration: \"none\",\n    color: \"#212F3C\",\n    //fontFamily: '-apple-system',\n  },\n  lateTitleFormat: {\n    paddingTop: \"20px\",\n    paddingBottom: \"10px\",\n    textDecoration: \"none\",\n    color: \"#212F3C\",\n    //fontFamily: '-apple-system',\n  },\n  titleParagraphFormat: {\n    fontFamily: \"-apple-system\",\n  },\n  titleParagraphFormat2: {\n    fontFamily: \"-apple-system\",\n    padding: \"10px\",\n  },\n  titleParagraphFormat3: {\n    fontFamily: \"-apple-system\",\n    padding: \"10px\",\n    fontWeight: \"bold\",\n  },\n  titleParagraphFormat4: {\n    fontFamily: \"-apple-system\",\n    paddingLeft: \"10px\",\n  },\n  imageFormat: {\n    width: \"50\",\n    height: \"50%\",\n    display: \"flex\",\n    alignItems: \"center\",\n    flexDirection: \"column\",\n    paddingTop: \"2%\",\n  },\n  imageFormat3: {\n    width: \"70%\",\n    height: \"70%\",\n    display: \"flex\",\n    alignItems: \"center\",\n    flexDirection: \"column\",\n    paddingTop: \"2%\",\n  },\n  imgwrapper: {\n    display: \"flex\",\n    alignItems: \"center\",\n    flexDirection: \"column\",\n    paddingTop: \"2%\",\n  },\n  refwrapper: {\n    display: \"flex\",\n    alignItems: \"center\",\n    flexDirection: \"column\",\n  },\n  refFormat: {\n    width: \"70%\",\n    height: \"70%\",\n    display: \"flex\",\n    alignItems: \"center\",\n    flexDirection: \"column\",\n  },\n}));\n\nconst FinalUpdate = ({ tagChange }) => {\n  const classes = useStyles();\n  //const theme = useTheme();\n\n  return (\n    <div className={classes.wrapper}>\n      <Header></Header>\n      <Box className={classes.boxFormat}>\n        <Typography align=\"center\" variant=\"h4\" className={classes.titleFormat}>\n          Introduction/Background\n        </Typography>\n        <Typography\n          align=\"left\"\n          variant=\"subtitle1\"\n          className={classes.titleParagraphFormat2}\n        >\n          Since the introduction of Siri, voice assistants have hugely impacted\n          people's experience with intelligent systems. However, this sudden fad\n          comes with challenges, with the most obvious one being distinguishing\n          human voice from background noises and silence, which necessitates\n          novel approaches to speech detection. To serve this endeavor, our\n          project utilizes machine learning methods to perform human speech\n          recognition against complex noise scenarios.\n        </Typography>\n\n        <Typography\n          align=\"center\"\n          variant=\"h4\"\n          className={classes.lateTitleFormat}\n        >\n          Problem Statement\n        </Typography>\n        <Typography\n          align=\"left\"\n          variant=\"subtitle1\"\n          className={classes.titleParagraphFormat2}\n        >\n          The fundamental problem is a binary classification. Given an audio\n          source, we aim to distinguition the time intervals containing human\n          speeches from the rest. Additionally, we would filter out background\n          noises of timestamps that are identified as containing speeches.\n        </Typography>\n\n        <Typography\n          align=\"center\"\n          variant=\"h4\"\n          className={classes.lateTitleFormat}\n        >\n          Method\n        </Typography>\n        <Typography\n          align=\"left\"\n          variant=\"h5\"\n          className={classes.titleParagraphFormat}\n        >\n          Dataset\n        </Typography>\n        <Typography\n          align=\"left\"\n          variant=\"subtitle1\"\n          className={classes.titleParagraphFormat2}\n        >\n          - Speech activity detection dataset from Kaggle: 3 sets of data, 738\n          files in total with their annotations<br></br>- Florida Bandmaster\n          Association (FBA) dataset<br></br>\n        </Typography>\n\n        <Typography\n          align=\"left\"\n          variant=\"h5\"\n          className={classes.titleParagraphFormat}\n        >\n          Working Process\n        </Typography>\n        <Typography\n          align=\"left\"\n          variant=\"subtitle1\"\n          className={classes.titleParagraphFormat2}\n        >\n          For training, accurate annotation of the segment boundaries separating\n          noise, silence, and speech part is required and essential. The dataset\n          we select includes annotation files in praat-textgrids form, so we\n          first need to write a data-preprocessing file to read in these files\n          and build a groundtruth matrix specifying labels of different parts of\n          the audio. Meanwhile, we need to read in the audio file and create a\n          sliding window moving on it, extracting features like mfcc and\n          spectral flux from different time intervals. The next step is to feed\n          our data to the pre-defined model to let the machine learn. We will\n          split our dataset to two parts, maybe 80% for training and 20% for\n          testing. Lastly, we will employ different evaluation methods in class\n          to access our model.\n        </Typography>\n\n        <Typography\n          align=\"left\"\n          variant=\"h5\"\n          className={classes.titleParagraphFormat}\n        >\n          {\" \"}\n          Training Method\n        </Typography>\n        <Typography\n          align=\"left\"\n          variant=\"subtitle1\"\n          className={classes.titleParagraphFormat2}\n        >\n          Noise, silence and human speech have very different audio features. To\n          distinguish them, we need to first understand how musical features map\n          input datapoints to their groups before later applying these rules to\n          classify hidden, or unseen inputs. <br></br>\n          <br></br>\n          We will compare the performances of popular classification algorithms\n          and then improve the winning model based on our specific use scenario.\n          <br></br>\n          <br></br> General Approach: Supervised Learning\n          <br></br> Candidate Models: SVM, Random Forest, CNN [1] <br></br>\n          Related Libraries: Numpy, Sklearn, Librosa<br></br>\n        </Typography>\n\n        <Typography\n          align=\"center\"\n          variant=\"h4\"\n          className={classes.lateTitleFormat}\n        >\n          Data Collection\n        </Typography>\n        <Typography\n          align=\"left\"\n          variant=\"h5\"\n          className={classes.titleParagraphFormat}\n        >\n          Data Preprocessing\n        </Typography>\n        <Typography\n          align=\"left\"\n          variant=\"subtitle1\"\n          className={classes.titleParagraphFormat2}\n        >\n          To start off the project, we turn raw audio files into tabular data\n          through signal processing techniques. In DataProcessing.py, we use\n          librosa to load and convert each audio file into a float array. We\n          then stack these arrays vertically and pad zero to those with shorter\n          length, forming a regular audio matrix, with each row as a different\n          audio file. We also return the average sampling rate in this file for\n          later use. In TextfileRead.py, we import textgrid and use this to\n          generate our groundtruth matrix. We achieve this by first constructing\n          a dummy zero matrix with the same shape as the audio matrix. Then we\n          read in different annotation files which label out every starting and\n          ending time of the human speech. We time each timestamp with the\n          sampling rate and get the index of the number we should start labeling\n          1. With this method, we go through all textgrid files and generate a\n          equal-sized matrix with annotations (labels).\n          <br></br>\n        </Typography>\n\n        <Typography\n          align=\"left\"\n          variant=\"h5\"\n          className={classes.titleParagraphFormat}\n        >\n          Feature Extraction\n        </Typography>\n        <Typography\n          align=\"left\"\n          variant=\"subtitle1\"\n          className={classes.titleParagraphFormat2}\n        >\n          To capture characteristics of audio files, we decided to generate 11\n          features which we think are crucial in classifying audio segment.\n          These features are zcr, rms, spectral_centroid, spectral_runoff and 13\n          coefficients of mfcc. The various features that we have extracted are\n          explained below. These features are common features that are\n          associated with sound recognition and spectrogram analysis. The goal\n          of the project is to separate speech audio from silences, we have\n          noted that not all these features would be needed but as we are\n          including data with noises, features such as mfcc improved the model\n          when non-speech noises are introduced.\n          <br></br>\n        </Typography>\n\n        <Typography\n          align=\"left\"\n          variant=\"h5\"\n          className={classes.titleParagraphFormat}\n        >\n          Feature Details\n        </Typography>\n        <Typography\n          align=\"left\"\n          variant=\"subtitle1\"\n          className={classes.titleParagraphFormat2}\n        >\n          All Ks here refer to the size of the processing block. And X(i) refers\n          to the signal value generated by the Librosa load() function.\n          <br></br>\n        </Typography>\n        <Typography\n          align=\"left\"\n          variant=\"subtitle1\"\n          className={classes.titleParagraphFormat3}\n        >\n          Zero Crossing Rate (ZCR)\n        </Typography>\n        <Typography\n          align=\"left\"\n          variant=\"subtitle1\"\n          className={classes.titleParagraphFormat4}\n        >\n          ZCR is a low-level feature describing the number of changes of sign in\n          consecutive blocks of the audio samples.\n          <div className={classes.imgwrapper}>\n            <img className={classes.imageFormat3} src={zcrFig} alt=\"...\"></img>\n          </div>\n          This function describes how often the signal content changes its sign\n          in the block. The bigger this value is, the more likely that this\n          block contains human voice / sound (any high-frequency content).\n        </Typography>\n\n        <Typography\n          align=\"left\"\n          variant=\"subtitle1\"\n          className={classes.titleParagraphFormat3}\n        >\n          Root Mean Square (RMS)\n        </Typography>\n        <Typography\n          align=\"left\"\n          variant=\"subtitle1\"\n          className={classes.titleParagraphFormat4}\n        >\n          RMS is also a low-level feature describing the intensity of the audio\n          signal.\n          <div className={classes.imgwrapper}>\n            <img className={classes.imageFormat3} src={rmsFig} alt=\"...\"></img>\n          </div>\n          This function describes the root mean square of the signal value in a\n          certain block. The higher this value is, the more likely there is\n          audio in this time period. It also helps smooth out the audio, as the\n          sharp increase of signal value will be smoothed out by other numbers\n          in the same time range.\n        </Typography>\n\n        <Typography\n          align=\"left\"\n          variant=\"subtitle1\"\n          className={classes.titleParagraphFormat3}\n        >\n          Spectral Centroid\n        </Typography>\n        <Typography\n          align=\"left\"\n          variant=\"subtitle1\"\n          className={classes.titleParagraphFormat4}\n        >\n          Spectral Centroid describes the center of gravity of the spectral\n          energy, which is defined as the frequency-weighted sum of the power\n          spectrum.\n          <div className={classes.imgwrapper}>\n            <img\n              className={classes.imageFormat3}\n              src={spectralcentroidFig}\n              alt=\"...\"\n            ></img>\n          </div>\n          This feature describes the ratio of high-frequency to low-frequency in\n          the certain block.\n        </Typography>\n\n        <Typography\n          align=\"left\"\n          variant=\"subtitle1\"\n          className={classes.titleParagraphFormat3}\n        >\n          Spectral Rolloff\n        </Typography>\n        <Typography\n          align=\"left\"\n          variant=\"subtitle1\"\n          className={classes.titleParagraphFormat4}\n        >\n          The spectral rolloff measures the bandwidth of the analyzed block. It\n          is described as the frequency bin below which the magnitudes of the\n          short-time Fourier Transform of the x(i) reaches a certain percentage\n          of the overall magnitude. Basically, it defines how much energy is\n          lied under a specific frequency.\n          <div className={classes.imgwrapper}>\n            <img\n              className={classes.imageFormat}\n              src={spectralrolloffFig}\n              alt=\"...\"\n            ></img>\n          </div>\n        </Typography>\n\n        <Typography\n          align=\"left\"\n          variant=\"subtitle1\"\n          className={classes.titleParagraphFormat3}\n        >\n          Mel-Frequency Cepstral Coefficients (MFCC)\n        </Typography>\n        <Typography\n          align=\"left\"\n          variant=\"subtitle1\"\n          className={classes.titleParagraphFormat4}\n        >\n          <div className={classes.imgwrapper}>\n            <img className={classes.imageFormat} src={mfccFig} alt=\"...\"></img>\n          </div>\n          <br></br>\n          MFCC is a series of coefficients describing the shape of the\n          spectrogram of the audio. The jth coefficient is calculated using the\n          following formula.\n          <div className={classes.imgwrapper}>\n            <img\n              className={classes.imageFormat3}\n              src={mfccFig2}\n              alt=\"...\"\n            ></img>\n          </div>\n        </Typography>\n\n        <Typography\n          align=\"left\"\n          variant=\"subtitle1\"\n          className={classes.titleParagraphFormat3}\n        >\n          Spectral Flux\n        </Typography>\n        <Typography\n          align=\"left\"\n          variant=\"subtitle1\"\n          className={classes.titleParagraphFormat4}\n        >\n          Spectral flux defines the amount of change of the spectral shape,\n          which is usually calculated by the average different between Fourier\n          Transform frames. Spectral flux is also a good indicator describing\n          the spectrogram shape of the audio signal.\n        </Typography>\n\n        <Typography\n          align=\"left\"\n          variant=\"subtitle1\"\n          className={classes.titleParagraphFormat3}\n        >\n          Spectral Crest\n        </Typography>\n        <Typography\n          align=\"left\"\n          variant=\"subtitle1\"\n          className={classes.titleParagraphFormat4}\n        >\n          Spectral crest factor measures the tonal characteristic. It compares\n          the maximum magnitude of the power spectrum with the sum of the\n          magnitude spectrum.\n          <div className={classes.imgwrapper}>\n            <img\n              className={classes.imageFormat2}\n              src={spectralcrest}\n              alt=\"...\"\n            ></img>\n          </div>\n          <br></br>\n          Tonal characteristic generally refers to the ratio between tonal\n          components and noisy components.\n        </Typography>\n\n        <Typography\n          align=\"center\"\n          variant=\"h4\"\n          className={classes.lateTitleFormat}\n        >\n          Model Training\n        </Typography>\n        <Typography\n          align=\"left\"\n          variant=\"subtitle1\"\n          className={classes.titleParagraphFormat2}\n        >\n          After pre-processing and feature extraction, we implemented three\n          different training menthods to test results and evaluating outputs:\n          Random Forest, Adaboost (Adaptive Boosting) and SVM (Support Vector\n          Machine). We chose these model based on the idea that ensemble\n          learning models excel non-ensemble models in solving classification\n          problems (both bagging and boosting), and SVM is designed to work with\n          high-dimension data and offers good generalization to avoiid\n          overfitting, which is applicable to our use case.\n          <br></br>\n          <br></br>\n          Since we have 11 individual data sources with different features, in\n          order to involve all possible situations (Male and Female, with and\n          without background noise), we decided to combine all data files to\n          generate one dataset with all information, given that all data files\n          have 2 labels only: a row of data is labeled either \"true\" (speech) or\n          \"false\" (non-speech).\n          <br></br>\n          <br></br>\n          For each of the three classification models mentioned above, we then\n          conduct K-fold cross validation to split the dataset into 5 folds,\n          leaving 80% of the data for training, and 20% for testing in each of\n          the five trials. For each trial, we set the expected predictive model\n          accordingly and apply evaulation metrics in order to take average in\n          the end. Since our dataset is balanced and the models we use\n          inherently work with unbalanced datasets, we only use Accuracy and F1\n          Score as performance metrics (see the following section).\n          <br></br>\n        </Typography>\n\n        <Typography\n          align=\"center\"\n          variant=\"h4\"\n          className={classes.lateTitleFormat}\n        >\n          Performance Evaluation\n        </Typography>\n        <Typography\n          align=\"left\"\n          variant=\"subtitle1\"\n          className={classes.titleParagraphFormat2}\n        >\n          We use 2 metrics to evaluate model performance: Average Accuracy and\n          Average F1 score. The former one can show the correctness of our model\n          predictions directly while the latter one informs us how precise the\n          results are.\n          <br></br>\n          Evaluation results for three training models are shown in figure\n          below. Noticed that all three Average Accuracy values are above 86%\n          and all Average F-1 scores are above 87%, as shown in the figuure\n          below.\n          <br></br>\n          <div className={classes.imgwrapper}>\n            <img\n              className={classes.imageFormat3}\n              src={trainingresult}\n              alt=\"...\"\n            ></img>\n          </div>\n          <br></br>\n          We also calculate feature importances during each trial so that we can\n          understand what features influence predictions the most and reevaluate\n          our working during the \"Data Preprocessing\" and \"Feature Extraction\"\n          stages. //////To gain insights into how individual features contribute\n          to classification, we generate feature importances of our selected\n          features with our Random Forest classifier and Adaboost classiifier\n          (as shown below).\n          <div className={classes.imgwrapper}>\n            <img className={classes.imageFormat3} src={rfFI} alt=\"...\"></img>\n          </div>\n          <div className={classes.imgwrapper}>\n            <img className={classes.imageFormat3} src={adbFI} alt=\"...\"></img>\n          </div>\n          <br></br>\n          We observe that both models believe Root Mean Square (RMS) of audio\n          signal intensity to be more important in classifying human speeches\n          compared to other features, while the models do not agree on the\n          importance of Spectral Flux and Spectral Centroid.\n          <br></br>\n          <br></br>\n          Since Random Forest classifier yields the best performance according\n          to our metrics, focus on this classifier exclusively and try to\n          optimize the model throughconducting hyperparameter tuning. We set\n          different hyperparameters values (n, split and leaf values) and did\n          six trials in total. All the six trials results had an accuracy above\n          90% for PCA = 8 or PCA = 10, which means that our model had a high\n          quality of predicting outputs such that it won't change in a big scale\n          for different hyperparameters values. Plots for the model accuracy for\n          six trials are shown in figure below.\n          <br></br>\n          <div className={classes.imgwrapper}>\n            <img className={classes.imageFormat} src={hyper} alt=\"...\"></img>\n          </div>\n        </Typography>\n\n        <Typography\n          align=\"center\"\n          variant=\"h4\"\n          className={classes.lateTitleFormat}\n        >\n          Conclusion\n        </Typography>\n        <Typography\n          align=\"left\"\n          variant=\"subtitle1\"\n          className={classes.titleParagraphFormat2}\n        >\n          Since all three predictive models we set have pretty high average\n          accuracy (above 86%) and average F-1 (above 87%) values, we believe\n          our models can produce reliable predictions on whether a certain time\n          interval has human speeching audio or not given a random speeching\n          audio input. Among the three training models, Random Forest has the\n          best output results (above 90.5% accuracy and 90.8% F-1 scores). We\n          believe this is because the provided resource dataset is very large,\n          which allow the training model to avoid overfitting and learn the data\n          comprehensively. Also, the feature importances plots we set during our\n          \"Data Preprocessing\" and \"Model Training\" stages allow the model to\n          remove irrelevant attributes and focus on features that have bigger\n          influences to perform in a better way.\n        </Typography>\n        <Typography\n          align=\"center\"\n          variant=\"h4\"\n          className={classes.lateTitleFormat}\n        >\n          Timeline and Team Work Assignment\n        </Typography>\n        <Typography\n          align=\"left\"\n          variant=\"h5\"\n          className={classes.titleParagraphFormat}\n        >\n          Proposal (October 7th)\n        </Typography>\n        <Typography\n          align=\"left\"\n          variant=\"subtitle1\"\n          className={classes.titleParagraphFormat2}\n        >\n          Dataset, approach, report - October 3rd\n          <br></br>\n          Review cotent and finish proposal - October 7th\n          <br></br>\n          <br></br>\n        </Typography>\n\n        <Typography\n          align=\"left\"\n          variant=\"h5\"\n          className={classes.titleParagraphFormat}\n        >\n          Midterm Report (November 16th)\n        </Typography>\n        <Typography\n          align=\"left\"\n          variant=\"subtitle1\"\n          className={classes.titleParagraphFormat2}\n        >\n          Research and architectural design (Team) - October 15th\n          <br></br>\n          Data collection and preprocessing (Haojun, Yulong) - October 31st\n          <br></br>\n          Train and validate first approach and finish report after evaluation\n          (Bruce, Zeyu, Yulai) - November 16th\n          <br></br>\n          Further improve our model by adjusting parameters and optimizing the\n          code (Team) - November 21th\n          <br></br>\n          <br></br>\n        </Typography>\n\n        <Typography\n          align=\"left\"\n          variant=\"h5\"\n          className={classes.titleParagraphFormat}\n        >\n          Final Report (December 7th)\n        </Typography>\n        <Typography\n          align=\"left\"\n          variant=\"subtitle1\"\n          className={classes.titleParagraphFormat2}\n        >\n          Add distinguishing feature of approach (Team) - November 25th\n          <br></br>\n          Review entire project and finish final report (Team) - December 7th\n          <br></br>\n          <br></br>\n        </Typography>\n\n        <Typography\n          align=\"center\"\n          variant=\"h4\"\n          className={classes.lateTitleFormat}\n        >\n          References\n        </Typography>\n        <div className={classes.refwrapper}>\n          <img className={classes.refFormat} src={ref} alt=\"...\"></img>\n        </div>\n      </Box>\n    </div>\n  );\n};\n\nexport default FinalUpdate;\n"]},"metadata":{},"sourceType":"module"}