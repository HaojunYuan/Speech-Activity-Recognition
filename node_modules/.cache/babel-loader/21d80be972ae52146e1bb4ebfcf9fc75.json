{"ast":null,"code":"var _jsxFileName = \"/Users/brian/Desktop/ML/Speech-Activity-Recognition/src/pages/Proposal/Proposal.js\",\n    _s = $RefreshSig$();\n\nimport React from \"react\";\nimport { Typography, Box } from \"@material-ui/core\";\nimport { makeStyles } from \"@material-ui/core/styles\";\nimport { Header } from \"../../components\";\nimport ref from \"../../img/references.png\"; //import { Link } from 'react-router-dom';\n\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst useStyles = makeStyles(theme => ({\n  wrapper: {\n    display: \"flex\",\n    alignItems: \"center\",\n    flexDirection: \"column\",\n    paddingTop: \"20px\"\n  },\n  link: {\n    textDecoration: \"none\",\n    color: \"#000\"\n  },\n  titleFormat: {\n    paddingBottom: \"10px\",\n    textDecoration: \"none\",\n    color: \"#212F3C\" //fontFamily: '-apple-system',\n\n  },\n  lateTitleFormat: {\n    paddingTop: \"20px\",\n    paddingBottom: \"10px\",\n    textDecoration: \"none\",\n    color: \"#212F3C\" //fontFamily: '-apple-system',\n\n  },\n  titleParagraphFormat: {\n    fontFamily: \"-apple-system\"\n  },\n  titleParagraphFormat2: {\n    fontFamily: \"-apple-system\",\n    padding: \"15px\"\n  },\n  boxFormat: {\n    width: \"70%\",\n    paddingBottom: \"30px\"\n  },\n  imgwrapper: {\n    display: \"flex\",\n    alignItems: \"center\",\n    flexDirection: \"column\",\n    paddingTop: \"2%\"\n  }\n}));\n\nconst Proposal = ({\n  tagChange\n}) => {\n  _s();\n\n  const classes = useStyles(); //const theme = useTheme();\n\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: classes.wrapper,\n    children: [/*#__PURE__*/_jsxDEV(Header, {}, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 58,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(Box, {\n      className: classes.boxFormat,\n      children: [/*#__PURE__*/_jsxDEV(Typography, {\n        align: \"center\",\n        variant: \"h4\",\n        className: classes.titleFormat,\n        children: \"Introduction/Background\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 60,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"subtitle1\",\n        className: classes.titleParagraphFormat2,\n        children: \"Since the introduction of Siri, voice assistants have hugely impacted people's experience with intelligent systems. However, this sudden fad comes with challenges, with the most obvious one being distinguishing human voice from background noises and silence, which necessitates novel approaches to speech detection. To serve this endeavor, our project utilizes machine learning methods to perform human speech recognition against complex noise scenarios.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 63,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"center\",\n        variant: \"h4\",\n        className: classes.lateTitleFormat,\n        children: \"Problem Statement\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 77,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"subtitle1\",\n        className: classes.titleParagraphFormat2,\n        children: \"The fundamental problem is a binary classification. Given an audio source, we aim to distinguition the time intervals containing human speeches from the rest. Additionally, we would filter out background noises of timestamps that are identified as containing speeches.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 84,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"center\",\n        variant: \"h4\",\n        className: classes.lateTitleFormat,\n        children: \"Method\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 95,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"h5\",\n        className: classes.titleParagraphFormat,\n        children: \"Dataset\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 102,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"subtitle1\",\n        className: classes.titleParagraphFormat2,\n        children: [\"- Speech activity detection dataset from Kaggle: 3 sets of data, 738 files in total with their annotations\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 115,\n          columnNumber: 48\n        }, this), \"- Florida Bandmaster Association (FBA) dataset\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 116,\n          columnNumber: 36\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 109,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"h5\",\n        className: classes.titleParagraphFormat,\n        children: \"Working Process\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 119,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"subtitle1\",\n        className: classes.titleParagraphFormat2,\n        children: \"For training, accurate annotation of the segment boundaries separating noise, silence, and speech part is required and essential. The dataset we select includes annotation files in praat-textgrids form, so we first need to write a data-preprocessing file to read in these files and build a groundtruth matrix specifying labels of different parts of the audio. Meanwhile, we need to read in the audio file and create a sliding window moving on it, extracting features like mfcc and spectral flux from different time intervals. The next step is to feed our data to the pre-defined model to let the machine learn. We will split our dataset to two parts, maybe 80% for training and 20% for testing. Lastly, we will employ different evaluation methods in class to access our model.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 126,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"h5\",\n        className: classes.titleParagraphFormat,\n        children: [\" \", \"Training Method\"]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 145,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"subtitle1\",\n        className: classes.titleParagraphFormat2,\n        children: [\"Noise, silence and human speech have very different audio features. To distinguish them, we need to first understand how musical features map input datapoints to their groups before later applying these rules to classify hidden, or unseen inputs. \", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 161,\n          columnNumber: 46\n        }, this), \"We will compare the performances of popular classification algorithms and then improve the winning model based on our specific use scenario.\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 164,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 165,\n          columnNumber: 11\n        }, this), \" General Approach: Supervised Learning\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 166,\n          columnNumber: 11\n        }, this), \" Candidate Models: SVM, Random Forest, CNN [1] \", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 166,\n          columnNumber: 67\n        }, this), \"Related Libraries: Numpy, Sklearn, Librosa\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 167,\n          columnNumber: 53\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 153,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"center\",\n        variant: \"h4\",\n        className: classes.lateTitleFormat,\n        children: \"Potentional Results and Evaluation\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 170,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"h5\",\n        className: classes.titleParagraphFormat,\n        children: \"Potential Results\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 177,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"subtitle1\",\n        className: classes.titleParagraphFormat2,\n        children: [\"Our first goal is to build a model that takes in an audio file, detects human speech activity and labels the corresponding time intervals. It will then filter any noise within these intervals and output clean audio. Our model should work with both simple models like silence and speech appears in sequence and complex models that human speech is mixed with different background noises. The expected accuracy rate is 90%.\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 195,\n          columnNumber: 32\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 184,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"h5\",\n        className: classes.titleParagraphFormat,\n        children: \"Evaluation\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 198,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"subtitle1\",\n        className: classes.titleParagraphFormat2,\n        children: [\"Having a small portion of data as testing group, we will deploy F-measure we studied in class to compute precision, recall and accuracy and evaluate the model based on these statistics.\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 212,\n          columnNumber: 69\n        }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 213,\n          columnNumber: 11\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 205,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"center\",\n        variant: \"h4\",\n        className: classes.lateTitleFormat,\n        children: \"Timeline and Team Work Assignment\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 216,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"h5\",\n        className: classes.titleParagraphFormat,\n        children: \"Proposal (October 7th)\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 223,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"subtitle1\",\n        className: classes.titleParagraphFormat2,\n        children: [\"Dataset, approach, report - October 3rd\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 236,\n          columnNumber: 11\n        }, this), \"Review cotent and finish proposal - October 7th\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 238,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 239,\n          columnNumber: 11\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 230,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"h5\",\n        className: classes.titleParagraphFormat,\n        children: \"Midterm Report (November 16th)\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 242,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"subtitle1\",\n        className: classes.titleParagraphFormat2,\n        children: [\"Research and architectural design (Team) - October 15th\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 255,\n          columnNumber: 11\n        }, this), \"Data collection and preprocessing (Haojun, Yulong) - October 31st\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 257,\n          columnNumber: 11\n        }, this), \"Train and validate first approach and finish report after evaluation (Bruce, Zeyu, Yulai) - November 16th\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 260,\n          columnNumber: 11\n        }, this), \"Further improve our model by adjusting parameters and optimizing the code (Team) - November 21th\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 263,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 264,\n          columnNumber: 11\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 249,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"h5\",\n        className: classes.titleParagraphFormat,\n        children: \"Final Report (December 7th)\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 267,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"left\",\n        variant: \"subtitle1\",\n        className: classes.titleParagraphFormat2,\n        children: [\"Add distinguishing feature of approach (Team) - November 25th\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 280,\n          columnNumber: 11\n        }, this), \"Review entire project and finish final report (Team) - December 7th\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 282,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 283,\n          columnNumber: 11\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 274,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(Typography, {\n        align: \"center\",\n        variant: \"h4\",\n        className: classes.lateTitleFormat,\n        children: \"References\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 286,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n        className: classes.imgwrapper,\n        children: /*#__PURE__*/_jsxDEV(\"img\", {\n          className: classes.imageFormat,\n          src: ref,\n          alt: \"...\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 294,\n          columnNumber: 11\n        }, this)\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 293,\n        columnNumber: 9\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 59,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 57,\n    columnNumber: 5\n  }, this);\n};\n\n_s(Proposal, \"8g5FPXexvSEOsxdmU7HicukHGqY=\", false, function () {\n  return [useStyles];\n});\n\n_c = Proposal;\nexport default Proposal;\n\nvar _c;\n\n$RefreshReg$(_c, \"Proposal\");","map":{"version":3,"sources":["/Users/brian/Desktop/ML/Speech-Activity-Recognition/src/pages/Proposal/Proposal.js"],"names":["React","Typography","Box","makeStyles","Header","ref","useStyles","theme","wrapper","display","alignItems","flexDirection","paddingTop","link","textDecoration","color","titleFormat","paddingBottom","lateTitleFormat","titleParagraphFormat","fontFamily","titleParagraphFormat2","padding","boxFormat","width","imgwrapper","Proposal","tagChange","classes","imageFormat"],"mappings":";;;AAAA,OAAOA,KAAP,MAAkB,OAAlB;AAEA,SAASC,UAAT,EAAqBC,GAArB,QAAgC,mBAAhC;AACA,SAASC,UAAT,QAA2B,0BAA3B;AACA,SAASC,MAAT,QAAuB,kBAAvB;AACA,OAAOC,GAAP,MAAgB,0BAAhB,C,CACA;;;AAEA,MAAMC,SAAS,GAAGH,UAAU,CAAEI,KAAD,KAAY;AACvCC,EAAAA,OAAO,EAAE;AACPC,IAAAA,OAAO,EAAE,MADF;AAEPC,IAAAA,UAAU,EAAE,QAFL;AAGPC,IAAAA,aAAa,EAAE,QAHR;AAIPC,IAAAA,UAAU,EAAE;AAJL,GAD8B;AAOvCC,EAAAA,IAAI,EAAE;AACJC,IAAAA,cAAc,EAAE,MADZ;AAEJC,IAAAA,KAAK,EAAE;AAFH,GAPiC;AAWvCC,EAAAA,WAAW,EAAE;AACXC,IAAAA,aAAa,EAAE,MADJ;AAEXH,IAAAA,cAAc,EAAE,MAFL;AAGXC,IAAAA,KAAK,EAAE,SAHI,CAIX;;AAJW,GAX0B;AAiBvCG,EAAAA,eAAe,EAAE;AACfN,IAAAA,UAAU,EAAE,MADG;AAEfK,IAAAA,aAAa,EAAE,MAFA;AAGfH,IAAAA,cAAc,EAAE,MAHD;AAIfC,IAAAA,KAAK,EAAE,SAJQ,CAKf;;AALe,GAjBsB;AAwBvCI,EAAAA,oBAAoB,EAAE;AACpBC,IAAAA,UAAU,EAAE;AADQ,GAxBiB;AA2BvCC,EAAAA,qBAAqB,EAAE;AACrBD,IAAAA,UAAU,EAAE,eADS;AAErBE,IAAAA,OAAO,EAAE;AAFY,GA3BgB;AA+BvCC,EAAAA,SAAS,EAAE;AACTC,IAAAA,KAAK,EAAE,KADE;AAETP,IAAAA,aAAa,EAAE;AAFN,GA/B4B;AAmCvCQ,EAAAA,UAAU,EAAE;AACVhB,IAAAA,OAAO,EAAE,MADC;AAEVC,IAAAA,UAAU,EAAE,QAFF;AAGVC,IAAAA,aAAa,EAAE,QAHL;AAIVC,IAAAA,UAAU,EAAE;AAJF;AAnC2B,CAAZ,CAAD,CAA5B;;AA2CA,MAAMc,QAAQ,GAAG,CAAC;AAAEC,EAAAA;AAAF,CAAD,KAAmB;AAAA;;AAClC,QAAMC,OAAO,GAAGtB,SAAS,EAAzB,CADkC,CAElC;;AAEA,sBACE;AAAK,IAAA,SAAS,EAAEsB,OAAO,CAACpB,OAAxB;AAAA,4BACE,QAAC,MAAD;AAAA;AAAA;AAAA;AAAA,YADF,eAEE,QAAC,GAAD;AAAK,MAAA,SAAS,EAAEoB,OAAO,CAACL,SAAxB;AAAA,8BACE,QAAC,UAAD;AAAY,QAAA,KAAK,EAAC,QAAlB;AAA2B,QAAA,OAAO,EAAC,IAAnC;AAAwC,QAAA,SAAS,EAAEK,OAAO,CAACZ,WAA3D;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cADF,eAIE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,WAFV;AAGE,QAAA,SAAS,EAAEY,OAAO,CAACP,qBAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAJF,eAkBE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,QADR;AAEE,QAAA,OAAO,EAAC,IAFV;AAGE,QAAA,SAAS,EAAEO,OAAO,CAACV,eAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAlBF,eAyBE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,WAFV;AAGE,QAAA,SAAS,EAAEU,OAAO,CAACP,qBAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAzBF,eAoCE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,QADR;AAEE,QAAA,OAAO,EAAC,IAFV;AAGE,QAAA,SAAS,EAAEO,OAAO,CAACV,eAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cApCF,eA2CE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,IAFV;AAGE,QAAA,SAAS,EAAEU,OAAO,CAACT,oBAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cA3CF,eAkDE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,WAFV;AAGE,QAAA,SAAS,EAAES,OAAO,CAACP,qBAHrB;AAAA,8IAMuC;AAAA;AAAA;AAAA;AAAA,gBANvC,iEAO2B;AAAA;AAAA;AAAA;AAAA,gBAP3B;AAAA;AAAA;AAAA;AAAA;AAAA,cAlDF,eA4DE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,IAFV;AAGE,QAAA,SAAS,EAAEO,OAAO,CAACT,oBAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cA5DF,eAmEE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,WAFV;AAGE,QAAA,SAAS,EAAES,OAAO,CAACP,qBAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAnEF,eAsFE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,IAFV;AAGE,QAAA,SAAS,EAAEO,OAAO,CAACT,oBAHrB;AAAA,mBAKG,GALH;AAAA;AAAA;AAAA;AAAA;AAAA,cAtFF,eA8FE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,WAFV;AAGE,QAAA,SAAS,EAAES,OAAO,CAACP,qBAHrB;AAAA,2RAQqC;AAAA;AAAA;AAAA;AAAA,gBARrC,+JAWE;AAAA;AAAA;AAAA;AAAA,gBAXF,eAYE;AAAA;AAAA;AAAA;AAAA,gBAZF,yDAaE;AAAA;AAAA;AAAA;AAAA,gBAbF,kEAa0D;AAAA;AAAA;AAAA;AAAA,gBAb1D,6DAc4C;AAAA;AAAA;AAAA;AAAA,gBAd5C;AAAA;AAAA;AAAA;AAAA;AAAA,cA9FF,eA+GE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,QADR;AAEE,QAAA,OAAO,EAAC,IAFV;AAGE,QAAA,SAAS,EAAEO,OAAO,CAACV,eAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cA/GF,eAsHE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,IAFV;AAGE,QAAA,SAAS,EAAEU,OAAO,CAACT,oBAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAtHF,eA6HE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,WAFV;AAGE,QAAA,SAAS,EAAES,OAAO,CAACP,qBAHrB;AAAA,wcAWuB;AAAA;AAAA;AAAA;AAAA,gBAXvB;AAAA;AAAA;AAAA;AAAA;AAAA,cA7HF,eA2IE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,IAFV;AAGE,QAAA,SAAS,EAAEO,OAAO,CAACT,oBAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cA3IF,eAkJE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,WAFV;AAGE,QAAA,SAAS,EAAES,OAAO,CAACP,qBAHrB;AAAA,6NAO4D;AAAA;AAAA;AAAA;AAAA,gBAP5D,eAQE;AAAA;AAAA;AAAA;AAAA,gBARF;AAAA;AAAA;AAAA;AAAA;AAAA,cAlJF,eA6JE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,QADR;AAEE,QAAA,OAAO,EAAC,IAFV;AAGE,QAAA,SAAS,EAAEO,OAAO,CAACV,eAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cA7JF,eAoKE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,IAFV;AAGE,QAAA,SAAS,EAAEU,OAAO,CAACT,oBAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cApKF,eA2KE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,WAFV;AAGE,QAAA,SAAS,EAAES,OAAO,CAACP,qBAHrB;AAAA,2EAME;AAAA;AAAA;AAAA;AAAA,gBANF,kEAQE;AAAA;AAAA;AAAA;AAAA,gBARF,eASE;AAAA;AAAA;AAAA;AAAA,gBATF;AAAA;AAAA;AAAA;AAAA;AAAA,cA3KF,eAuLE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,IAFV;AAGE,QAAA,SAAS,EAAEO,OAAO,CAACT,oBAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAvLF,eA8LE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,WAFV;AAGE,QAAA,SAAS,EAAES,OAAO,CAACP,qBAHrB;AAAA,2FAME;AAAA;AAAA;AAAA;AAAA,gBANF,oFAQE;AAAA;AAAA;AAAA;AAAA,gBARF,4HAWE;AAAA;AAAA;AAAA;AAAA,gBAXF,mHAcE;AAAA;AAAA;AAAA;AAAA,gBAdF,eAeE;AAAA;AAAA;AAAA;AAAA,gBAfF;AAAA;AAAA;AAAA;AAAA;AAAA,cA9LF,eAgNE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,IAFV;AAGE,QAAA,SAAS,EAAEO,OAAO,CAACT,oBAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAhNF,eAuNE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,MADR;AAEE,QAAA,OAAO,EAAC,WAFV;AAGE,QAAA,SAAS,EAAES,OAAO,CAACP,qBAHrB;AAAA,iGAME;AAAA;AAAA;AAAA;AAAA,gBANF,sFAQE;AAAA;AAAA;AAAA;AAAA,gBARF,eASE;AAAA;AAAA;AAAA;AAAA,gBATF;AAAA;AAAA;AAAA;AAAA;AAAA,cAvNF,eAmOE,QAAC,UAAD;AACE,QAAA,KAAK,EAAC,QADR;AAEE,QAAA,OAAO,EAAC,IAFV;AAGE,QAAA,SAAS,EAAEO,OAAO,CAACV,eAHrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAnOF,eA0OE;AAAK,QAAA,SAAS,EAAEU,OAAO,CAACH,UAAxB;AAAA,+BACE;AAAK,UAAA,SAAS,EAAEG,OAAO,CAACC,WAAxB;AAAqC,UAAA,GAAG,EAAExB,GAA1C;AAA+C,UAAA,GAAG,EAAC;AAAnD;AAAA;AAAA;AAAA;AAAA;AADF;AAAA;AAAA;AAAA;AAAA,cA1OF;AAAA;AAAA;AAAA;AAAA;AAAA,YAFF;AAAA;AAAA;AAAA;AAAA;AAAA,UADF;AAmPD,CAvPD;;GAAMqB,Q;UACYpB,S;;;KADZoB,Q;AAyPN,eAAeA,QAAf","sourcesContent":["import React from \"react\";\n\nimport { Typography, Box } from \"@material-ui/core\";\nimport { makeStyles } from \"@material-ui/core/styles\";\nimport { Header } from \"../../components\";\nimport ref from \"../../img/references.png\";\n//import { Link } from 'react-router-dom';\n\nconst useStyles = makeStyles((theme) => ({\n  wrapper: {\n    display: \"flex\",\n    alignItems: \"center\",\n    flexDirection: \"column\",\n    paddingTop: \"20px\",\n  },\n  link: {\n    textDecoration: \"none\",\n    color: \"#000\",\n  },\n  titleFormat: {\n    paddingBottom: \"10px\",\n    textDecoration: \"none\",\n    color: \"#212F3C\",\n    //fontFamily: '-apple-system',\n  },\n  lateTitleFormat: {\n    paddingTop: \"20px\",\n    paddingBottom: \"10px\",\n    textDecoration: \"none\",\n    color: \"#212F3C\",\n    //fontFamily: '-apple-system',\n  },\n  titleParagraphFormat: {\n    fontFamily: \"-apple-system\",\n  },\n  titleParagraphFormat2: {\n    fontFamily: \"-apple-system\",\n    padding: \"15px\",\n  },\n  boxFormat: {\n    width: \"70%\",\n    paddingBottom: \"30px\",\n  },\n  imgwrapper: {\n    display: \"flex\",\n    alignItems: \"center\",\n    flexDirection: \"column\",\n    paddingTop: \"2%\",\n  },\n}));\n\nconst Proposal = ({ tagChange }) => {\n  const classes = useStyles();\n  //const theme = useTheme();\n\n  return (\n    <div className={classes.wrapper}>\n      <Header></Header>\n      <Box className={classes.boxFormat}>\n        <Typography align=\"center\" variant=\"h4\" className={classes.titleFormat}>\n          Introduction/Background\n        </Typography>\n        <Typography\n          align=\"left\"\n          variant=\"subtitle1\"\n          className={classes.titleParagraphFormat2}\n        >\n          Since the introduction of Siri, voice assistants have hugely impacted\n          people's experience with intelligent systems. However, this sudden fad\n          comes with challenges, with the most obvious one being distinguishing\n          human voice from background noises and silence, which necessitates\n          novel approaches to speech detection. To serve this endeavor, our\n          project utilizes machine learning methods to perform human speech\n          recognition against complex noise scenarios.\n        </Typography>\n\n        <Typography\n          align=\"center\"\n          variant=\"h4\"\n          className={classes.lateTitleFormat}\n        >\n          Problem Statement\n        </Typography>\n        <Typography\n          align=\"left\"\n          variant=\"subtitle1\"\n          className={classes.titleParagraphFormat2}\n        >\n          The fundamental problem is a binary classification. Given an audio\n          source, we aim to distinguition the time intervals containing human\n          speeches from the rest. Additionally, we would filter out background\n          noises of timestamps that are identified as containing speeches.\n        </Typography>\n\n        <Typography\n          align=\"center\"\n          variant=\"h4\"\n          className={classes.lateTitleFormat}\n        >\n          Method\n        </Typography>\n        <Typography\n          align=\"left\"\n          variant=\"h5\"\n          className={classes.titleParagraphFormat}\n        >\n          Dataset\n        </Typography>\n        <Typography\n          align=\"left\"\n          variant=\"subtitle1\"\n          className={classes.titleParagraphFormat2}\n        >\n          - Speech activity detection dataset from Kaggle: 3 sets of data, 738\n          files in total with their annotations<br></br>- Florida Bandmaster\n          Association (FBA) dataset<br></br>\n        </Typography>\n\n        <Typography\n          align=\"left\"\n          variant=\"h5\"\n          className={classes.titleParagraphFormat}\n        >\n          Working Process\n        </Typography>\n        <Typography\n          align=\"left\"\n          variant=\"subtitle1\"\n          className={classes.titleParagraphFormat2}\n        >\n          For training, accurate annotation of the segment boundaries separating\n          noise, silence, and speech part is required and essential. The dataset\n          we select includes annotation files in praat-textgrids form, so we\n          first need to write a data-preprocessing file to read in these files\n          and build a groundtruth matrix specifying labels of different parts of\n          the audio. Meanwhile, we need to read in the audio file and create a\n          sliding window moving on it, extracting features like mfcc and\n          spectral flux from different time intervals. The next step is to feed\n          our data to the pre-defined model to let the machine learn. We will\n          split our dataset to two parts, maybe 80% for training and 20% for\n          testing. Lastly, we will employ different evaluation methods in class\n          to access our model.\n        </Typography>\n\n        <Typography\n          align=\"left\"\n          variant=\"h5\"\n          className={classes.titleParagraphFormat}\n        >\n          {\" \"}\n          Training Method\n        </Typography>\n        <Typography\n          align=\"left\"\n          variant=\"subtitle1\"\n          className={classes.titleParagraphFormat2}\n        >\n          Noise, silence and human speech have very different audio features. To\n          distinguish them, we need to first understand how musical features map\n          input datapoints to their groups before later applying these rules to\n          classify hidden, or unseen inputs. <br></br>\n          We will compare the performances of popular classification algorithms\n          and then improve the winning model based on our specific use scenario.\n          <br></br>\n          <br></br> General Approach: Supervised Learning\n          <br></br> Candidate Models: SVM, Random Forest, CNN [1] <br></br>\n          Related Libraries: Numpy, Sklearn, Librosa<br></br>\n        </Typography>\n\n        <Typography\n          align=\"center\"\n          variant=\"h4\"\n          className={classes.lateTitleFormat}\n        >\n          Potentional Results and Evaluation\n        </Typography>\n        <Typography\n          align=\"left\"\n          variant=\"h5\"\n          className={classes.titleParagraphFormat}\n        >\n          Potential Results\n        </Typography>\n        <Typography\n          align=\"left\"\n          variant=\"subtitle1\"\n          className={classes.titleParagraphFormat2}\n        >\n          Our first goal is to build a model that takes in an audio file,\n          detects human speech activity and labels the corresponding time\n          intervals. It will then filter any noise within these intervals and\n          output clean audio. Our model should work with both simple models like\n          silence and speech appears in sequence and complex models that human\n          speech is mixed with different background noises. The expected\n          accuracy rate is 90%.<br></br>\n        </Typography>\n\n        <Typography\n          align=\"left\"\n          variant=\"h5\"\n          className={classes.titleParagraphFormat}\n        >\n          Evaluation\n        </Typography>\n        <Typography\n          align=\"left\"\n          variant=\"subtitle1\"\n          className={classes.titleParagraphFormat2}\n        >\n          Having a small portion of data as testing group, we will deploy\n          F-measure we studied in class to compute precision, recall and\n          accuracy and evaluate the model based on these statistics.<br></br>\n          <br></br>\n        </Typography>\n\n        <Typography\n          align=\"center\"\n          variant=\"h4\"\n          className={classes.lateTitleFormat}\n        >\n          Timeline and Team Work Assignment\n        </Typography>\n        <Typography\n          align=\"left\"\n          variant=\"h5\"\n          className={classes.titleParagraphFormat}\n        >\n          Proposal (October 7th)\n        </Typography>\n        <Typography\n          align=\"left\"\n          variant=\"subtitle1\"\n          className={classes.titleParagraphFormat2}\n        >\n          Dataset, approach, report - October 3rd\n          <br></br>\n          Review cotent and finish proposal - October 7th\n          <br></br>\n          <br></br>\n        </Typography>\n\n        <Typography\n          align=\"left\"\n          variant=\"h5\"\n          className={classes.titleParagraphFormat}\n        >\n          Midterm Report (November 16th)\n        </Typography>\n        <Typography\n          align=\"left\"\n          variant=\"subtitle1\"\n          className={classes.titleParagraphFormat2}\n        >\n          Research and architectural design (Team) - October 15th\n          <br></br>\n          Data collection and preprocessing (Haojun, Yulong) - October 31st\n          <br></br>\n          Train and validate first approach and finish report after evaluation\n          (Bruce, Zeyu, Yulai) - November 16th\n          <br></br>\n          Further improve our model by adjusting parameters and optimizing the\n          code (Team) - November 21th\n          <br></br>\n          <br></br>\n        </Typography>\n\n        <Typography\n          align=\"left\"\n          variant=\"h5\"\n          className={classes.titleParagraphFormat}\n        >\n          Final Report (December 7th)\n        </Typography>\n        <Typography\n          align=\"left\"\n          variant=\"subtitle1\"\n          className={classes.titleParagraphFormat2}\n        >\n          Add distinguishing feature of approach (Team) - November 25th\n          <br></br>\n          Review entire project and finish final report (Team) - December 7th\n          <br></br>\n          <br></br>\n        </Typography>\n\n        <Typography\n          align=\"center\"\n          variant=\"h4\"\n          className={classes.lateTitleFormat}\n        >\n          References\n        </Typography>\n        <div className={classes.imgwrapper}>\n          <img className={classes.imageFormat} src={ref} alt=\"...\"></img>\n        </div>\n      </Box>\n    </div>\n  );\n};\n\nexport default Proposal;\n"]},"metadata":{},"sourceType":"module"}